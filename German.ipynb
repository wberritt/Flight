{"cells": [{"metadata": {}, "cell_type": "code", "source": "import os, types\nimport pandas as pd\nfrom botocore.client import Config\nimport ibm_boto3\n\ndef __iter__(self): return 0\n\n# @hidden_cell\n# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n# You might want to remove those credentials before you share the notebook.\n\nif os.environ.get('RUNTIME_ENV_LOCATION_TYPE') == 'external':\n    endpoint_f3fdba9d244c401187e179ad818538ca = 'https://s3.us.cloud-object-storage.appdomain.cloud'\nelse:\n    endpoint_f3fdba9d244c401187e179ad818538ca = 'https://s3.private.us.cloud-object-storage.appdomain.cloud'\n\nclient_f3fdba9d244c401187e179ad818538ca = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id='0v4d8hCD7rL44oC69GjDH3_pOadslP7Lnvq2zyPTqGiU',\n    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\n    config=Config(signature_version='oauth'),\n    endpoint_url=endpoint_f3fdba9d244c401187e179ad818538ca)\n\nbody = client_f3fdba9d244c401187e179ad818538ca.get_object(Bucket='germancreditrisk-donotdelete-pr-ttjhbh8c1w4avk',Key='german_credit_data.csv')['Body']\n# add missing __iter__ method, so pandas accepts body as file-like object\nif not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n\ndf1= pd.read_csv(body)\ndf1.head()\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Delete unnecessary columns\ndel df1['Unnamed: 0']\ndf1.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Deal with NaN/Missing values\ndf1.info()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Create Dataframe to run regression to solve missing values\ndfsolve = df1.dropna()\ndfsolve.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "dfsolve = dfsolve.rename(columns={'Saving accounts': 'Saccounts', 'Checking account': 'Caccount'})\ndf1 = df1.rename(columns={'Saving accounts': 'Saccounts', 'Checking account': 'Caccount'})", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "print(dfsolve[\"Saccounts\"].unique())\nprint(dfsolve[\"Caccount\"].unique())\nprint(dfsolve[\"Housing\"].unique())", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "dfsolve['saving']=dfsolve.Saccounts.map({'little':0, 'moderate':1, 'rich':2, 'quite rich':3})\ndfsolve['checking']=dfsolve.Caccount.map({'little':0, 'moderate':1, 'rich':2,})\ndfsolve['MorF']=dfsolve.Sex.map({'male':0, 'female':1})\ndfsolve['Homepay']=dfsolve.Housing.map({'free':0, 'rent':1, 'own':2})\ndfsolve.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Predict Savings Account amount\nimport numpy as np\nfrom sklearn import linear_model\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.model_selection import train_test_split\nx=dfsolve[['MorF', 'Job', 'Homepay',]]\ny=dfsolve[['saving']]\nregr = linear_model.LinearRegression()\nregr.fit(x,y)\nprint(regr.coef_)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "x1=dfsolve[['MorF', 'Job', 'Homepay']]\ny1=dfsolve[['checking']]\nregr1 = linear_model.LinearRegression()\nregr1.fit(x1,y1)\nprint(regr1.coef_)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "results = regr.score(x, y)\nprint(results)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "y.head(50)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "predict = regr.predict(x)\npredict[0:50]", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "import seaborn as sns\nsns.heatmap(dfsolve.corr(), annot=True)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "df1['Saccounts'].hist()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "print(df1['Saccounts'].value_counts())\nprint(df1['Caccount'].value_counts())", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "print (603/817)\nprint (103/817)\nprint (63/817)\nprint (48/817)\n\nprint(274/606)\nprint(269/606)\nprint(63/606)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "df1['Saccounts'] = df1['Saccounts'].fillna(pd.Series(np.random.choice(['little', 'quite rich', 'rich', 'moderate'], \n                                                      p=[0.738, 0.126, 0.077, .059], size=len(df1))))\ndf1.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "df1['Caccount'] = df1['Caccount'].fillna(pd.Series(np.random.choice(['little','rich', 'moderate'], \n                                                      p=[0.45, 0.44, 0.11], size=len(df1))))\ndf1.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "print(df1['Purpose'].unique())\nprint(df1['Risk'].unique())\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "df1['Risk Outcome']=df1.Risk.map({'bad':0, 'good':1})\ndel df1['Risk']", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "interval = (18, 25, 35, 60, 120)\n\nGroup = ['Student', 'Young', 'Adult', 'Senior']\ndf1[\"Age Group\"] = pd.cut(df1.Age, interval, labels=Group)\ndel df1['Age']\ndf1.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "df2=pd.get_dummies(df1)\ndf2.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "x=df2.loc[:, df2.columns != 'Risk Outcome']\ny=df2[['Risk Outcome']]", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.2)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "df2.info()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "regr=linear_model.LogisticRegression()\nregr.fit(xtrain,ytrain)\nprint(regr.coef_)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "from sklearn.tree import DecisionTreeClassifier\nclf = DecisionTreeClassifier().fit(xtrain, ytrain)\nclfresults = clf.score(xtest, ytest)\nprint(clfresults)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "critclf = DecisionTreeClassifier(criterion=\"gini\")\ncritclf = clf.fit(xtrain, ytrain)\ncritclfresults = clf.score(xtest,ytest)\nprint(critclfresults)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression, LinearRegression, Ridge, Lasso, ElasticNet\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import mean_squared_error, r2_score, accuracy_score, confusion_matrix, classification_report, fbeta_score  \nfrom sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV\n\n\nseed = 7\nmodels = []\nmodels.append(('LGR', LogisticRegression()))\nmodels.append(('LDA', LinearDiscriminantAnalysis()))\nmodels.append(('KNN', KNeighborsClassifier()))\nmodels.append(('CART', DecisionTreeClassifier()))\nmodels.append(('NB', GaussianNB()))\nmodels.append(('RF', RandomForestClassifier()))\nmodels.append(('SVM', SVC(gamma='auto')))\nmodels.append(('XGBM', XGBClassifier()))\nmodels.append(('LGBM', LGBMClassifier()))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "results = []\nnames = []\nscoring = 'recall'\n\nfor name, model in models:\n        kfold = KFold(n_splits=10, random_state=seed)\n        cv_results = cross_val_score(model, xtrain, ytrain, cv=kfold, scoring=scoring)\n        results.append(cv_results)\n        names.append(name)\n        msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n        print(msg)\n\nfig = plt.figure(figsize=(11,6))\nfig.suptitle('Algorithms Compare')\nax = fig.add_subplot(111)\ngreen_diamond = dict(markerfacecolor='g', marker='D')\nplt.boxplot(results, flierprops=green_diamond, patch_artist=True)\nax.set_xticklabels(names)\nplt.show()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.7", "language": "python"}, "language_info": {"name": "python", "version": "3.7.10", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}